{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6a537b-1e69-4c5e-b02a-c16c2ccc85a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ENVIRONMENT VALIDATION & REPRODUCIBILITY CONTROL\n",
    "# ============================================================\n",
    "\n",
    "# Display Python version for experiment traceability\n",
    "!python --version \n",
    "# ensure python 3.9.12 for similar results as ours is used thruought the environment\n",
    "\n",
    "# For  reproducibility:\n",
    "# Recommended stable versions (TensorFlow 2.14 + TF Privacy 0.9)\n",
    "# Uncomment only if environment setup is required\n",
    "\n",
    "# !pip uninstall tensorflow -y\n",
    "# !pip uninstall tensorflow-privacy -y\n",
    "# !pip install tensorflow==2.14.0\n",
    "# !pip install tensorflow-privacy==0.9.0\n",
    "# !pip install deap imbalanced-learn seaborn\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Set deterministic seeds for full reproducibility\n",
    "# ------------------------------------------------------------\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "print(\"Deterministic seed set to:\", SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5fc695-ee70-4346-9358-63e0e5acb697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7c462b-3469-41a6-bc41-3e640829c27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# LIBRARY IMPORTS\n",
    "# ============================================================\n",
    "\n",
    "# ---------------------------\n",
    "# Standard Library\n",
    "# ---------------------------\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# ---------------------------\n",
    "# Data & Numerical\n",
    "# ---------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------\n",
    "# Visualization\n",
    "# ---------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ---------------------------\n",
    "# performance Machine Learning\n",
    "# ---------------------------\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    precision_recall_curve,\n",
    "    auc\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# Deep Learning\n",
    "# ---------------------------\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# ---------------------------\n",
    "# Differential Privacy\n",
    "# ---------------------------\n",
    "import tensorflow_privacy\n",
    "from tensorflow_privacy.privacy.analysis.compute_dp_sgd_privacy import compute_dp_sgd_privacy\n",
    "\n",
    "# ---------------------------\n",
    "# Genetic Algorithm\n",
    "# ---------------------------\n",
    "from deap import base, creator, tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3392c48-48a8-4679-86e1-51638ff5eb43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1c4e45-838d-4a17-beb1-9af5401c1e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DATA LOADING\n",
    "# ============================================================\n",
    "\n",
    "# IMPORTANT:\n",
    "# Replace with relative path for reproducibility \n",
    "DATA_PATH = \"BotNeTIoT-L01_label_NoDuplicates.csv\"\n",
    "\n",
    "data = pd.read_csv(DATA_PATH, index_col=0)\n",
    "\n",
    "target_column = \"label\"\n",
    "\n",
    "print(\"Unique Labels:\", data[target_column].unique())\n",
    "print(\"Number of Classes:\", data[target_column].nunique())\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Feature / Target Split\n",
    "# ------------------------------------------------------------\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Train / Validation / Test Split\n",
    "# 60% train | 15% validation | 25% test\n",
    "# ------------------------------------------------------------\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.25, stratify=y, random_state=SEED\n",
    ")\n",
    "\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.4, stratify=y_temp, random_state=SEED\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Standard Scaling (fit ONLY on training set)\n",
    "# Prevents data leakage\n",
    "# ------------------------------------------------------------\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "print(\"Data preprocessing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355031e2-e10d-43ba-be35-8f6205b3c380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d52e07-707b-4022-91b0-268c3299eff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# GENETIC ALGORITHM SEARCH SPACE DEFINITION\n",
    "# ============================================================\n",
    "\n",
    "# LSTM layer width candidates\n",
    "LSTM_UNITS = [16, 32, 64, 128, 256]\n",
    "\n",
    "# Fully connected layer width candidates\n",
    "DENSE_UNITS = [16, 32, 64, 128, 256]\n",
    "\n",
    "# Activation candidates (used in Dense layers)\n",
    "ACTIVATIONS = ['relu', 'gelu', 'swish']\n",
    "\n",
    "# Optimizer choice (NOTE: DP requires DP-SGD internally)\n",
    "OPTIMIZERS = ['sgd']   # constrained due to DP implementation\n",
    "\n",
    "# For softmax(2) output we use categorical crossentropy\n",
    "LOSSES = ['categorical_crossentropy']\n",
    "\n",
    "# Learning rate search grid\n",
    "LEARNING_RATES = [1e-3, 1e-4]\n",
    "\n",
    "# Batch size candidates\n",
    "BATCH_SIZES = [64, 128, 256]\n",
    "\n",
    "# Epoch search grid\n",
    "EPOCHS = [20, 30, 50, 100]\n",
    "\n",
    "# Architectural depth constraints\n",
    "MAX_LSTM_LAYERS = 3\n",
    "MAX_DENSE_LAYERS = 4\n",
    "\n",
    "# Differential Privacy defaults\n",
    "DEFAULT_NOISE_MULTIPLIER = 1.3\n",
    "DELTA = 1e-5\n",
    "\n",
    "# Toggle GA execution\n",
    "gene_alg = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3b85cd-b4a5-423d-8cb1-69c844d18c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000f2ab7-b70f-4f3f-85e9-218d7a8c0913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# RANDOM HYPERPARAMETER SAMPLER\n",
    "# ============================================================\n",
    "\n",
    "def create_hyperparameter_set_dp():\n",
    "    \"\"\"\n",
    "    Randomly generates a valid hyperparameter configuration\n",
    "    for DP-LSTM architecture search.\n",
    "    \"\"\"\n",
    "\n",
    "    n_lstm = random.randint(1, MAX_LSTM_LAYERS)\n",
    "    n_dense = random.randint(1, MAX_DENSE_LAYERS)\n",
    "\n",
    "    total_layers = n_lstm + n_dense\n",
    "\n",
    "    return {\n",
    "        \"lstm_units\": [random.choice(LSTM_UNITS) for _ in range(n_lstm)],\n",
    "        \"dense_units\": [random.choice(DENSE_UNITS) for _ in range(n_dense)],\n",
    "        \"dropouts\": [random.uniform(0.1, 0.5) for _ in range(total_layers)],\n",
    "        \"activation\": random.choice(ACTIVATIONS),\n",
    "        \"optimizer\": \"sgd\",  # constrained for DP\n",
    "        \"losses\": \"categorical_crossentropy\",\n",
    "        \"learning_rate\": random.choice(LEARNING_RATES),\n",
    "        \"batch_size\": random.choice(BATCH_SIZES),\n",
    "        \"epochs\": random.choice(EPOCHS),\n",
    "        \"l2_norm_clip\": random.uniform(0.5, 2.0),\n",
    "        \"noise_multiplier\": random.uniform(0.8, 1.5)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef330b5-1211-44f4-8e88-aa8d2a94f2cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517458d4-01fa-432c-9a2d-e15bcbda5068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FITNESS FUNCTION: DP-LSTM WITH STRATIFIED 5-FOLD CV\n",
    "# ============================================================\n",
    "\n",
    "def evaluate_lstm_with_dp(hyperparams):\n",
    "    \"\"\"\n",
    "    Evaluates a DP-LSTM configuration using 5-fold\n",
    "    stratified cross-validation.\n",
    "\n",
    "    Fitness Objective:\n",
    "        Maximize (Mean F1 Score - Epsilon)\n",
    "\n",
    "    This encourages privacy-utility trade-off optimization.\n",
    "    \"\"\"\n",
    "\n",
    "    # ---------------------------\n",
    "    # Extract Hyperparameters\n",
    "    # ---------------------------\n",
    "    lstm_units       = hyperparams[\"lstm_units\"]\n",
    "    dense_units      = hyperparams[\"dense_units\"]\n",
    "    dropouts         = hyperparams[\"dropouts\"]\n",
    "    activation       = hyperparams[\"activation\"]\n",
    "    learning_rate    = hyperparams[\"learning_rate\"]\n",
    "    batch_size       = hyperparams[\"batch_size\"]\n",
    "    epochs           = hyperparams[\"epochs\"]\n",
    "    l2_norm_clip     = hyperparams[\"l2_norm_clip\"]\n",
    "    noise_multiplier = hyperparams[\"noise_multiplier\"]\n",
    "\n",
    "    # ---------------------------\n",
    "    # Reshape input for LSTM\n",
    "    # Shape: (samples, timesteps=1, features)\n",
    "    # ---------------------------\n",
    "    X_seq = np.expand_dims(X_train_scaled, axis=1)\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    f1_scores = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_seq, y_train):\n",
    "\n",
    "        # IMPORTANT: rebuild model each fold (prevents weight leakage)\n",
    "        model = build_dp_lstm_model(\n",
    "            input_dim=X_train_scaled.shape[1],\n",
    "            lstm_units=lstm_units,\n",
    "            dense_units=dense_units,\n",
    "            dropouts=dropouts,\n",
    "            learning_rate=learning_rate,\n",
    "            l2_norm_clip=l2_norm_clip,\n",
    "            noise_multiplier=noise_multiplier\n",
    "        )\n",
    "\n",
    "        X_tr, X_val = X_seq[train_idx], X_seq[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        y_tr_cat = tf.keras.utils.to_categorical(y_tr, 2)\n",
    "        y_val_cat = tf.keras.utils.to_categorical(y_val, 2)\n",
    "\n",
    "        model.fit(\n",
    "            X_tr,\n",
    "            y_tr_cat,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        y_pred = model.predict(X_val, verbose=0).argmax(axis=1)\n",
    "\n",
    "        f1_scores.append(f1_score(y_val, y_pred))\n",
    "\n",
    "    # ---------------------------\n",
    "    # Privacy Accounting\n",
    "    # ---------------------------\n",
    "    epsilon, _ = compute_dp_sgd_privacy(\n",
    "        n=len(X_train),\n",
    "        batch_size=batch_size,\n",
    "        noise_multiplier=noise_multiplier,\n",
    "        epochs=epochs,\n",
    "        delta=DELTA\n",
    "    )\n",
    "\n",
    "    # ---------------------------\n",
    "    # GA Fitness Objective Fitness=α⋅F1−β⋅ε\n",
    "    # ---------------------------\n",
    "    fitness = np.mean(f1_scores) - epsilon\n",
    "\n",
    "    return (fitness,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03138d8-423e-408f-bbdd-463896ae0080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd882f5-82aa-43e0-90f2-b54df46c9004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f082afc-ad01-4318-a4e3-4040315a74bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FUNCTION: Build Differentially Private LSTM Model\n",
    "# ============================================================\n",
    "\n",
    "def build_dp_lstm_model(input_dim,\n",
    "                        lstm_units,\n",
    "                        dense_units,\n",
    "                        dropouts,\n",
    "                        learning_rate,\n",
    "                        l2_norm_clip,\n",
    "                        noise_multiplier):\n",
    "\n",
    "    \"\"\"\n",
    "    Constructs a Differentially Private LSTM model.\n",
    "\n",
    "    Parameters:\n",
    "        input_dim: number of input features\n",
    "        lstm_units: list of LSTM layer sizes\n",
    "        dense_units: list of Dense layer sizes\n",
    "        dropouts: list of dropout values per layer\n",
    "        learning_rate: optimizer learning rate\n",
    "        l2_norm_clip: gradient clipping threshold (DP parameter)\n",
    "        noise_multiplier: Gaussian noise scale (DP parameter)\n",
    "\n",
    "    Returns:\n",
    "        Compiled Keras model\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Reshape input to (samples, timesteps=1, features)\n",
    "    model.add(LSTM(\n",
    "        lstm_units[0],\n",
    "        return_sequences=(len(lstm_units) > 1),\n",
    "        input_shape=(1, input_dim)\n",
    "    ))\n",
    "    model.add(Dropout(dropouts[0]))\n",
    "\n",
    "    # Additional LSTM layers\n",
    "    for i in range(1, len(lstm_units)):\n",
    "        model.add(LSTM(\n",
    "            lstm_units[i],\n",
    "            return_sequences=(i < len(lstm_units) - 1)\n",
    "        ))\n",
    "        model.add(Dropout(dropouts[i]))\n",
    "\n",
    "    # Dense layers\n",
    "    offset = len(lstm_units)\n",
    "    for j, units in enumerate(dense_units):\n",
    "        model.add(Dense(units, activation='relu'))\n",
    "        model.add(Dropout(dropouts[offset + j]))\n",
    "\n",
    "    # Output layer (Binary classification)\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    # Differentially Private Optimizer\n",
    "    optimizer = tensorflow_privacy.DPKerasSGDOptimizer(\n",
    "        l2_norm_clip=l2_norm_clip,\n",
    "        noise_multiplier=noise_multiplier,\n",
    "        num_microbatches=1,\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249034e8-53d4-4dfe-9a91-0686c7e44595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7c2da4-deec-4cd2-a0ca-b372abc1ecf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CROSS-VALIDATION (Correctly Reinitialize Model Each Fold)\n",
    "# ============================================================\n",
    "\n",
    "def cross_validate_model(params):\n",
    "\n",
    "    X_seq = np.expand_dims(X_train_scaled, axis=1)\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    f1_scores = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_seq, y_train):\n",
    "\n",
    "        model = build_dp_lstm_model(\n",
    "            input_dim=X_train_scaled.shape[1],\n",
    "            lstm_units=params[\"lstm_units\"],\n",
    "            dense_units=params[\"dense_units\"],\n",
    "            dropouts=params[\"dropouts\"],\n",
    "            learning_rate=params[\"learning_rate\"],\n",
    "            l2_norm_clip=params[\"l2_norm_clip\"],\n",
    "            noise_multiplier=params[\"noise_multiplier\"]\n",
    "        )\n",
    "\n",
    "        X_tr, X_val = X_seq[train_idx], X_seq[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        y_tr_cat = to_categorical(y_tr, 2)\n",
    "        y_val_cat = to_categorical(y_val, 2)\n",
    "\n",
    "        model.fit(X_tr, y_tr_cat,\n",
    "                  epochs=params[\"epochs\"],\n",
    "                  batch_size=params[\"batch_size\"],\n",
    "                  verbose=0)\n",
    "\n",
    "        y_pred = model.predict(X_val, verbose=0).argmax(axis=1)\n",
    "\n",
    "        f1_scores.append(f1_score(y_val, y_pred))\n",
    "\n",
    "    return np.mean(f1_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcaa8f3-7c8c-4fbf-b389-562ff2d89353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be6da86-7500-4048-9aae-42b7f925edf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PRIVACY BUDGET COMPUTATION and Calculation\n",
    "# ============================================================\n",
    "\n",
    "def compute_privacy_budget(sample_size, batch_size,\n",
    "                           noise_multiplier, epochs,\n",
    "                           delta=1e-5):\n",
    "\n",
    "    \"\"\"\n",
    "    Computes epsilon using analytical RDP moments accountant.\n",
    "    \"\"\"\n",
    "\n",
    "    epsilon, _ = compute_dp_sgd_privacy(\n",
    "        n=sample_size,\n",
    "        batch_size=batch_size,\n",
    "        noise_multiplier=noise_multiplier,\n",
    "        epochs=epochs,\n",
    "        delta=delta\n",
    "    )\n",
    "\n",
    "    return epsilon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5aaa9e-6283-460d-be67-7daf558f987e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ddb0a1-9d3b-4e02-a1e6-b0123081aba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FINAL MODEL TRAINING FALL back\n",
    "# ============================================================\n",
    "\n",
    "best_params = {\n",
    "    \"lstm_units\": [64],\n",
    "    \"dense_units\": [128],\n",
    "    \"dropouts\": [0.3, 0.3],\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"l2_norm_clip\": 1.0,\n",
    "    \"noise_multiplier\": 1.2,\n",
    "    \"epochs\": 30,\n",
    "    \"batch_size\": 64\n",
    "}\n",
    "\n",
    "X_train_seq = np.expand_dims(X_train_scaled, axis=1)\n",
    "X_test_seq  = np.expand_dims(X_test_scaled, axis=1)\n",
    "\n",
    "model = build_dp_lstm_model(\n",
    "    input_dim=X_train_scaled.shape[1],\n",
    "    lstm_units=best_params[\"lstm_units\"],\n",
    "    dense_units=best_params[\"dense_units\"],\n",
    "    dropouts=best_params[\"dropouts\"],\n",
    "    learning_rate=best_params[\"learning_rate\"],\n",
    "    l2_norm_clip=best_params[\"l2_norm_clip\"],\n",
    "    noise_multiplier=best_params[\"noise_multiplier\"]\n",
    ")\n",
    "\n",
    "y_train_cat = to_categorical(y_train, 2)\n",
    "y_test_cat  = to_categorical(y_test, 2)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_seq, y_train_cat,\n",
    "    epochs=best_params[\"epochs\"],\n",
    "    batch_size=best_params[\"batch_size\"],\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Evaluation\n",
    "# ------------------------------------------------------------\n",
    "y_pred_test = model.predict(X_test_seq).argmax(axis=1)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_test))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_test))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_test))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Privacy Report\n",
    "# ------------------------------------------------------------\n",
    "epsilon = compute_privacy_budget(\n",
    "    sample_size=len(X_train),\n",
    "    batch_size=best_params[\"batch_size\"],\n",
    "    noise_multiplier=best_params[\"noise_multiplier\"],\n",
    "    epochs=best_params[\"epochs\"]\n",
    ")\n",
    "\n",
    "print(f\"(ε, δ)-DP Guarantee: ε = {epsilon:.4f}, δ = 1e-5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4212e2eb-db9f-4651-85c9-6677646da804",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
